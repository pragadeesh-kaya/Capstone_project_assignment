{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e696d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"breast-cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87522d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959823cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8666a4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9658b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506ad606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0           M        17.99         10.38          122.80     1001.0   \n",
       "1           M        20.57         17.77          132.90     1326.0   \n",
       "2           M        19.69         21.25          130.00     1203.0   \n",
       "3           M        11.42         20.38           77.58      386.1   \n",
       "4           M        20.29         14.34          135.10     1297.0   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564         M        21.56         22.39          142.00     1479.0   \n",
       "565         M        20.13         28.25          131.20     1261.0   \n",
       "566         M        16.60         28.08          108.30      858.1   \n",
       "567         M        20.60         29.33          140.10     1265.0   \n",
       "568         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb9b145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave points_worst  symmetry_worst  fractal_dimension_worst  diagnosis_M\n",
       "0          17.99         10.38          122.80     1001.0          0.11840           0.27760         0.30010              0.14710         0.2419                 0.07871     1.0950      0.9053         8.589   153.40       0.006399         0.04904       0.05373            0.01587      0.03003              0.006193        25.380          17.33           184.60      2019.0           0.16220            0.66560           0.7119                0.2654          0.4601                  0.11890            1\n",
       "1          20.57         17.77          132.90     1326.0          0.08474           0.07864         0.08690              0.07017         0.1812                 0.05667     0.5435      0.7339         3.398    74.08       0.005225         0.01308       0.01860            0.01340      0.01389              0.003532        24.990          23.41           158.80      1956.0           0.12380            0.18660           0.2416                0.1860          0.2750                  0.08902            1\n",
       "2          19.69         21.25          130.00     1203.0          0.10960           0.15990         0.19740              0.12790         0.2069                 0.05999     0.7456      0.7869         4.585    94.03       0.006150         0.04006       0.03832            0.02058      0.02250              0.004571        23.570          25.53           152.50      1709.0           0.14440            0.42450           0.4504                0.2430          0.3613                  0.08758            1\n",
       "3          11.42         20.38           77.58      386.1          0.14250           0.28390         0.24140              0.10520         0.2597                 0.09744     0.4956      1.1560         3.445    27.23       0.009110         0.07458       0.05661            0.01867      0.05963              0.009208        14.910          26.50            98.87       567.7           0.20980            0.86630           0.6869                0.2575          0.6638                  0.17300            1\n",
       "4          20.29         14.34          135.10     1297.0          0.10030           0.13280         0.19800              0.10430         0.1809                 0.05883     0.7572      0.7813         5.438    94.44       0.011490         0.02461       0.05688            0.01885      0.01756              0.005115        22.540          16.67           152.20      1575.0           0.13740            0.20500           0.4000                0.1625          0.2364                  0.07678            1\n",
       "..           ...           ...             ...        ...              ...               ...             ...                  ...            ...                     ...        ...         ...           ...      ...            ...             ...           ...                ...          ...                   ...           ...            ...              ...         ...               ...                ...              ...                   ...             ...                      ...          ...\n",
       "564        21.56         22.39          142.00     1479.0          0.11100           0.11590         0.24390              0.13890         0.1726                 0.05623     1.1760      1.2560         7.673   158.70       0.010300         0.02891       0.05198            0.02454      0.01114              0.004239        25.450          26.40           166.10      2027.0           0.14100            0.21130           0.4107                0.2216          0.2060                  0.07115            1\n",
       "565        20.13         28.25          131.20     1261.0          0.09780           0.10340         0.14400              0.09791         0.1752                 0.05533     0.7655      2.4630         5.203    99.04       0.005769         0.02423       0.03950            0.01678      0.01898              0.002498        23.690          38.25           155.00      1731.0           0.11660            0.19220           0.3215                0.1628          0.2572                  0.06637            1\n",
       "566        16.60         28.08          108.30      858.1          0.08455           0.10230         0.09251              0.05302         0.1590                 0.05648     0.4564      1.0750         3.425    48.55       0.005903         0.03731       0.04730            0.01557      0.01318              0.003892        18.980          34.12           126.70      1124.0           0.11390            0.30940           0.3403                0.1418          0.2218                  0.07820            1\n",
       "567        20.60         29.33          140.10     1265.0          0.11780           0.27700         0.35140              0.15200         0.2397                 0.07016     0.7260      1.5950         5.772    86.22       0.006522         0.06158       0.07117            0.01664      0.02324              0.006185        25.740          39.42           184.60      1821.0           0.16500            0.86810           0.9387                0.2650          0.4087                  0.12400            1\n",
       "568         7.76         24.54           47.92      181.0          0.05263           0.04362         0.00000              0.00000         0.1587                 0.05884     0.3857      1.4280         2.548    19.15       0.007189         0.00466       0.00000            0.00000      0.02676              0.002783         9.456          30.37            59.16       268.6           0.08996            0.06444           0.0000                0.0000          0.2871                  0.07039            0\n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df,dtype=int,drop_first=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95487d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis_M\n",
       "0    357\n",
       "1    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis_M'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779fb83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst', 'diagnosis_M'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2baeb65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Univariate import Univariate\n",
    "\n",
    "quan,qual = Univariate.quanQual(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cd4e05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radius_mean',\n",
       " 'texture_mean',\n",
       " 'perimeter_mean',\n",
       " 'area_mean',\n",
       " 'smoothness_mean',\n",
       " 'compactness_mean',\n",
       " 'concavity_mean',\n",
       " 'concave points_mean',\n",
       " 'symmetry_mean',\n",
       " 'fractal_dimension_mean',\n",
       " 'radius_se',\n",
       " 'texture_se',\n",
       " 'perimeter_se',\n",
       " 'area_se',\n",
       " 'smoothness_se',\n",
       " 'compactness_se',\n",
       " 'concavity_se',\n",
       " 'concave points_se',\n",
       " 'symmetry_se',\n",
       " 'fractal_dimension_se',\n",
       " 'radius_worst',\n",
       " 'texture_worst',\n",
       " 'perimeter_worst',\n",
       " 'area_worst',\n",
       " 'smoothness_worst',\n",
       " 'compactness_worst',\n",
       " 'concavity_worst',\n",
       " 'concave points_worst',\n",
       " 'symmetry_worst',\n",
       " 'fractal_dimension_worst',\n",
       " 'diagnosis_M']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f35baa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae9300f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.09636</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>16.26919</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.372583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median</th>\n",
       "      <td>13.37</td>\n",
       "      <td>18.84</td>\n",
       "      <td>86.24</td>\n",
       "      <td>551.1</td>\n",
       "      <td>0.09587</td>\n",
       "      <td>0.09263</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>1.108</td>\n",
       "      <td>2.287</td>\n",
       "      <td>24.53</td>\n",
       "      <td>0.00638</td>\n",
       "      <td>0.02045</td>\n",
       "      <td>0.02589</td>\n",
       "      <td>0.01093</td>\n",
       "      <td>0.01873</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>14.97</td>\n",
       "      <td>25.41</td>\n",
       "      <td>97.66</td>\n",
       "      <td>686.5</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.09993</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.08004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mode</th>\n",
       "      <td>12.34</td>\n",
       "      <td>14.93</td>\n",
       "      <td>82.61</td>\n",
       "      <td>512.2</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.2204</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>1.778</td>\n",
       "      <td>16.64</td>\n",
       "      <td>0.00508</td>\n",
       "      <td>0.01104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01344</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>12.36</td>\n",
       "      <td>17.7</td>\n",
       "      <td>101.7</td>\n",
       "      <td>284.4</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.07427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1:25%</th>\n",
       "      <td>11.7</td>\n",
       "      <td>16.17</td>\n",
       "      <td>75.17</td>\n",
       "      <td>420.3</td>\n",
       "      <td>0.08637</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.02031</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.8339</td>\n",
       "      <td>1.606</td>\n",
       "      <td>17.85</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01509</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.01516</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>13.01</td>\n",
       "      <td>21.08</td>\n",
       "      <td>84.11</td>\n",
       "      <td>515.3</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.06493</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>0.07146</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2:50%</th>\n",
       "      <td>13.37</td>\n",
       "      <td>18.84</td>\n",
       "      <td>86.24</td>\n",
       "      <td>551.1</td>\n",
       "      <td>0.09587</td>\n",
       "      <td>0.09263</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>1.108</td>\n",
       "      <td>2.287</td>\n",
       "      <td>24.53</td>\n",
       "      <td>0.00638</td>\n",
       "      <td>0.02045</td>\n",
       "      <td>0.02589</td>\n",
       "      <td>0.01093</td>\n",
       "      <td>0.01873</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>14.97</td>\n",
       "      <td>25.41</td>\n",
       "      <td>97.66</td>\n",
       "      <td>686.5</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.09993</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.08004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3:75%</th>\n",
       "      <td>15.78</td>\n",
       "      <td>21.8</td>\n",
       "      <td>104.1</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.06612</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>1.474</td>\n",
       "      <td>3.357</td>\n",
       "      <td>45.19</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.03245</td>\n",
       "      <td>0.04205</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.02348</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>18.79</td>\n",
       "      <td>29.72</td>\n",
       "      <td>125.4</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.3391</td>\n",
       "      <td>0.3829</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.3179</td>\n",
       "      <td>0.09208</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>24.3716</td>\n",
       "      <td>30.652</td>\n",
       "      <td>165.724</td>\n",
       "      <td>1786.6</td>\n",
       "      <td>0.132888</td>\n",
       "      <td>0.277192</td>\n",
       "      <td>0.351688</td>\n",
       "      <td>0.164208</td>\n",
       "      <td>0.259564</td>\n",
       "      <td>0.085438</td>\n",
       "      <td>1.29132</td>\n",
       "      <td>2.91544</td>\n",
       "      <td>9.69004</td>\n",
       "      <td>177.684</td>\n",
       "      <td>0.017258</td>\n",
       "      <td>0.089872</td>\n",
       "      <td>0.122292</td>\n",
       "      <td>0.031194</td>\n",
       "      <td>0.052208</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>30.7628</td>\n",
       "      <td>41.8024</td>\n",
       "      <td>208.304</td>\n",
       "      <td>2918.16</td>\n",
       "      <td>0.188908</td>\n",
       "      <td>0.778644</td>\n",
       "      <td>0.90238</td>\n",
       "      <td>0.269216</td>\n",
       "      <td>0.486908</td>\n",
       "      <td>0.140628</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4:100%</th>\n",
       "      <td>28.11</td>\n",
       "      <td>39.28</td>\n",
       "      <td>188.5</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.4268</td>\n",
       "      <td>0.2012</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>2.873</td>\n",
       "      <td>4.885</td>\n",
       "      <td>21.98</td>\n",
       "      <td>542.2</td>\n",
       "      <td>0.03113</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.05279</td>\n",
       "      <td>0.07895</td>\n",
       "      <td>0.02984</td>\n",
       "      <td>36.04</td>\n",
       "      <td>49.54</td>\n",
       "      <td>251.2</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>1.058</td>\n",
       "      <td>1.252</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IQR</th>\n",
       "      <td>4.08</td>\n",
       "      <td>5.63</td>\n",
       "      <td>28.93</td>\n",
       "      <td>362.4</td>\n",
       "      <td>0.01893</td>\n",
       "      <td>0.06548</td>\n",
       "      <td>0.10114</td>\n",
       "      <td>0.05369</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.00842</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.6401</td>\n",
       "      <td>1.751</td>\n",
       "      <td>27.34</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>0.01937</td>\n",
       "      <td>0.02696</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.00832</td>\n",
       "      <td>0.00231</td>\n",
       "      <td>5.78</td>\n",
       "      <td>8.64</td>\n",
       "      <td>41.29</td>\n",
       "      <td>568.7</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.1919</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>0.09647</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.02062</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5rule</th>\n",
       "      <td>6.12</td>\n",
       "      <td>8.445</td>\n",
       "      <td>43.395</td>\n",
       "      <td>543.6</td>\n",
       "      <td>0.028395</td>\n",
       "      <td>0.09822</td>\n",
       "      <td>0.15171</td>\n",
       "      <td>0.080535</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.01263</td>\n",
       "      <td>0.36975</td>\n",
       "      <td>0.96015</td>\n",
       "      <td>2.6265</td>\n",
       "      <td>41.01</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.029055</td>\n",
       "      <td>0.04044</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>0.01248</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>8.67</td>\n",
       "      <td>12.96</td>\n",
       "      <td>61.935</td>\n",
       "      <td>853.05</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.28785</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>0.144705</td>\n",
       "      <td>0.10125</td>\n",
       "      <td>0.03093</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lesser</th>\n",
       "      <td>5.58</td>\n",
       "      <td>7.725</td>\n",
       "      <td>31.775</td>\n",
       "      <td>-123.3</td>\n",
       "      <td>0.057975</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>-0.12215</td>\n",
       "      <td>-0.060225</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>0.04507</td>\n",
       "      <td>-0.13735</td>\n",
       "      <td>-0.12625</td>\n",
       "      <td>-1.0205</td>\n",
       "      <td>-23.16</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>-0.015975</td>\n",
       "      <td>-0.02535</td>\n",
       "      <td>-0.00297</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>-0.001217</td>\n",
       "      <td>4.34</td>\n",
       "      <td>8.12</td>\n",
       "      <td>22.175</td>\n",
       "      <td>-337.75</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>-0.14065</td>\n",
       "      <td>-0.2881</td>\n",
       "      <td>-0.079775</td>\n",
       "      <td>0.14915</td>\n",
       "      <td>0.04053</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greater</th>\n",
       "      <td>21.9</td>\n",
       "      <td>30.245</td>\n",
       "      <td>147.495</td>\n",
       "      <td>1326.3</td>\n",
       "      <td>0.133695</td>\n",
       "      <td>0.22862</td>\n",
       "      <td>0.28241</td>\n",
       "      <td>0.154535</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>0.07875</td>\n",
       "      <td>0.84865</td>\n",
       "      <td>2.43415</td>\n",
       "      <td>5.9835</td>\n",
       "      <td>86.2</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>0.061505</td>\n",
       "      <td>0.08249</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>0.03596</td>\n",
       "      <td>0.008023</td>\n",
       "      <td>27.46</td>\n",
       "      <td>42.68</td>\n",
       "      <td>187.335</td>\n",
       "      <td>1937.05</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.62695</td>\n",
       "      <td>0.7855</td>\n",
       "      <td>0.306105</td>\n",
       "      <td>0.41915</td>\n",
       "      <td>0.12301</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>6.981</td>\n",
       "      <td>9.71</td>\n",
       "      <td>43.79</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.01938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.04996</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>0.3602</td>\n",
       "      <td>0.757</td>\n",
       "      <td>6.802</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>7.93</td>\n",
       "      <td>12.02</td>\n",
       "      <td>50.41</td>\n",
       "      <td>185.2</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.05504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>28.11</td>\n",
       "      <td>39.28</td>\n",
       "      <td>188.5</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.4268</td>\n",
       "      <td>0.2012</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>2.873</td>\n",
       "      <td>4.885</td>\n",
       "      <td>21.98</td>\n",
       "      <td>542.2</td>\n",
       "      <td>0.03113</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.05279</td>\n",
       "      <td>0.07895</td>\n",
       "      <td>0.02984</td>\n",
       "      <td>36.04</td>\n",
       "      <td>49.54</td>\n",
       "      <td>251.2</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>1.058</td>\n",
       "      <td>1.252</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurtosis</th>\n",
       "      <td>0.845522</td>\n",
       "      <td>0.758319</td>\n",
       "      <td>0.972214</td>\n",
       "      <td>3.652303</td>\n",
       "      <td>0.855975</td>\n",
       "      <td>1.65013</td>\n",
       "      <td>1.998638</td>\n",
       "      <td>1.066556</td>\n",
       "      <td>1.287933</td>\n",
       "      <td>3.005892</td>\n",
       "      <td>17.686726</td>\n",
       "      <td>5.349169</td>\n",
       "      <td>21.401905</td>\n",
       "      <td>49.209077</td>\n",
       "      <td>10.46984</td>\n",
       "      <td>5.106252</td>\n",
       "      <td>48.861395</td>\n",
       "      <td>5.126302</td>\n",
       "      <td>7.89613</td>\n",
       "      <td>26.280847</td>\n",
       "      <td>0.94409</td>\n",
       "      <td>0.224302</td>\n",
       "      <td>1.07015</td>\n",
       "      <td>4.396395</td>\n",
       "      <td>0.517825</td>\n",
       "      <td>3.039288</td>\n",
       "      <td>1.615253</td>\n",
       "      <td>-0.535535</td>\n",
       "      <td>4.44456</td>\n",
       "      <td>5.244611</td>\n",
       "      <td>-1.726811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skew</th>\n",
       "      <td>0.94238</td>\n",
       "      <td>0.65045</td>\n",
       "      <td>0.99065</td>\n",
       "      <td>1.645732</td>\n",
       "      <td>0.456324</td>\n",
       "      <td>1.190123</td>\n",
       "      <td>1.40118</td>\n",
       "      <td>1.17118</td>\n",
       "      <td>0.725609</td>\n",
       "      <td>1.304489</td>\n",
       "      <td>3.088612</td>\n",
       "      <td>1.646444</td>\n",
       "      <td>3.443615</td>\n",
       "      <td>5.447186</td>\n",
       "      <td>2.31445</td>\n",
       "      <td>1.902221</td>\n",
       "      <td>5.110463</td>\n",
       "      <td>1.444678</td>\n",
       "      <td>2.195133</td>\n",
       "      <td>3.923969</td>\n",
       "      <td>1.103115</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>1.128164</td>\n",
       "      <td>1.859373</td>\n",
       "      <td>0.415426</td>\n",
       "      <td>1.473555</td>\n",
       "      <td>1.150237</td>\n",
       "      <td>0.492616</td>\n",
       "      <td>1.433928</td>\n",
       "      <td>1.662579</td>\n",
       "      <td>0.528461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <td>12.41892</td>\n",
       "      <td>18.498909</td>\n",
       "      <td>590.44048</td>\n",
       "      <td>123843.554318</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.076902</td>\n",
       "      <td>0.304316</td>\n",
       "      <td>4.087896</td>\n",
       "      <td>2069.431583</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>23.360224</td>\n",
       "      <td>37.776483</td>\n",
       "      <td>1129.130847</td>\n",
       "      <td>324167.385102</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.024755</td>\n",
       "      <td>0.043524</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.234177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.07972</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.00706</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.00617</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         radius_mean texture_mean perimeter_mean      area_mean smoothness_mean compactness_mean concavity_mean concave points_mean symmetry_mean fractal_dimension_mean  radius_se texture_se perimeter_se      area_se smoothness_se compactness_se concavity_se concave points_se symmetry_se fractal_dimension_se radius_worst texture_worst perimeter_worst     area_worst smoothness_worst compactness_worst concavity_worst concave points_worst symmetry_worst fractal_dimension_worst diagnosis_M\n",
       "Mean       14.127292    19.289649      91.969033     654.889104         0.09636         0.104341       0.088799            0.048919      0.181162               0.062798   0.405172   1.216853     2.866059    40.337079      0.007041       0.025478     0.031894          0.011796    0.020542             0.003795     16.26919     25.677223      107.261213     880.583128         0.132369          0.254265        0.272188             0.114606       0.290076                0.083946    0.372583\n",
       "Median         13.37        18.84          86.24          551.1         0.09587          0.09263        0.06154              0.0335        0.1792                0.06154     0.3242      1.108        2.287        24.53       0.00638        0.02045      0.02589           0.01093     0.01873             0.003187        14.97         25.41           97.66          686.5           0.1313            0.2119          0.2267              0.09993         0.2822                 0.08004         0.0\n",
       "Mode           12.34        14.93          82.61          512.2          0.1007           0.1147            0.0                 0.0        0.1601                0.05667     0.2204     0.8561        1.778        16.64       0.00508        0.01104          0.0               0.0     0.01344             0.001784        12.36          17.7           101.7          284.4           0.1216            0.1486             0.0                  0.0         0.2226                 0.07427           0\n",
       "Q1:25%          11.7        16.17          75.17          420.3         0.08637          0.06492        0.02956             0.02031        0.1619                 0.0577     0.2324     0.8339        1.606        17.85      0.005169        0.01308      0.01509          0.007638     0.01516             0.002248        13.01         21.08           84.11          515.3           0.1166            0.1472          0.1145              0.06493         0.2504                 0.07146         0.0\n",
       "Q2:50%         13.37        18.84          86.24          551.1         0.09587          0.09263        0.06154              0.0335        0.1792                0.06154     0.3242      1.108        2.287        24.53       0.00638        0.02045      0.02589           0.01093     0.01873             0.003187        14.97         25.41           97.66          686.5           0.1313            0.2119          0.2267              0.09993         0.2822                 0.08004         0.0\n",
       "Q3:75%         15.78         21.8          104.1          782.7          0.1053           0.1304         0.1307               0.074        0.1957                0.06612     0.4789      1.474        3.357        45.19      0.008146        0.03245      0.04205           0.01471     0.02348             0.004558        18.79         29.72           125.4         1084.0            0.146            0.3391          0.3829               0.1614         0.3179                 0.09208         1.0\n",
       "99%          24.3716       30.652        165.724         1786.6        0.132888         0.277192       0.351688            0.164208      0.259564               0.085438    1.29132    2.91544      9.69004      177.684      0.017258       0.089872     0.122292          0.031194    0.052208              0.01265      30.7628       41.8024         208.304        2918.16         0.188908          0.778644         0.90238             0.269216       0.486908                0.140628         1.0\n",
       "Q4:100%        28.11        39.28          188.5         2501.0          0.1634           0.3454         0.4268              0.2012         0.304                0.09744      2.873      4.885        21.98        542.2       0.03113         0.1354        0.396           0.05279     0.07895              0.02984        36.04         49.54           251.2         4254.0           0.2226             1.058           1.252                0.291         0.6638                  0.2075         1.0\n",
       "IQR             4.08         5.63          28.93          362.4         0.01893          0.06548        0.10114             0.05369        0.0338                0.00842     0.2465     0.6401        1.751        27.34      0.002977        0.01937      0.02696          0.007072     0.00832              0.00231         5.78          8.64           41.29          568.7           0.0294            0.1919          0.2684              0.09647         0.0675                 0.02062         1.0\n",
       "1.5rule         6.12        8.445         43.395          543.6        0.028395          0.09822        0.15171            0.080535        0.0507                0.01263    0.36975    0.96015       2.6265        41.01      0.004466       0.029055      0.04044          0.010608     0.01248             0.003465         8.67         12.96          61.935         853.05           0.0441           0.28785          0.4026             0.144705        0.10125                 0.03093         1.5\n",
       "Lesser          5.58        7.725         31.775         -123.3        0.057975          -0.0333       -0.12215           -0.060225        0.1112                0.04507   -0.13735   -0.12625      -1.0205       -23.16      0.000703      -0.015975     -0.02535          -0.00297     0.00268            -0.001217         4.34          8.12          22.175        -337.75           0.0725          -0.14065         -0.2881            -0.079775        0.14915                 0.04053        -1.5\n",
       "Greater         21.9       30.245        147.495         1326.3        0.133695          0.22862        0.28241            0.154535        0.2464                0.07875    0.84865    2.43415       5.9835         86.2      0.012612       0.061505      0.08249          0.025318     0.03596             0.008023        27.46         42.68         187.335        1937.05           0.1901           0.62695          0.7855             0.306105        0.41915                 0.12301         2.5\n",
       "Min            6.981         9.71          43.79          143.5         0.05263          0.01938            0.0                 0.0         0.106                0.04996     0.1115     0.3602        0.757        6.802      0.001713       0.002252          0.0               0.0    0.007882             0.000895         7.93         12.02           50.41          185.2          0.07117           0.02729             0.0                  0.0         0.1565                 0.05504           0\n",
       "Max            28.11        39.28          188.5         2501.0          0.1634           0.3454         0.4268              0.2012         0.304                0.09744      2.873      4.885        21.98        542.2       0.03113         0.1354        0.396           0.05279     0.07895              0.02984        36.04         49.54           251.2         4254.0           0.2226             1.058           1.252                0.291         0.6638                  0.2075           1\n",
       "kurtosis    0.845522     0.758319       0.972214       3.652303        0.855975          1.65013       1.998638            1.066556      1.287933               3.005892  17.686726   5.349169    21.401905    49.209077      10.46984       5.106252    48.861395          5.126302     7.89613            26.280847      0.94409      0.224302         1.07015       4.396395         0.517825          3.039288        1.615253            -0.535535        4.44456                5.244611   -1.726811\n",
       "skew         0.94238      0.65045        0.99065       1.645732        0.456324         1.190123        1.40118             1.17118      0.725609               1.304489   3.088612   1.646444     3.443615     5.447186       2.31445       1.902221     5.110463          1.444678    2.195133             3.923969     1.103115      0.498321        1.128164       1.859373         0.415426          1.473555        1.150237             0.492616       1.433928                1.662579    0.528461\n",
       "Var         12.41892    18.498909      590.44048  123843.554318        0.000198         0.002789       0.006355            0.001506      0.000752                0.00005   0.076902   0.304316     4.087896  2069.431583      0.000009       0.000321     0.000911          0.000038    0.000068             0.000007    23.360224     37.776483     1129.130847  324167.385102         0.000521          0.024755        0.043524             0.004321       0.003828                0.000326    0.234177\n",
       "Std         3.524049     4.301036      24.298981     351.914129        0.014064         0.052813        0.07972            0.038803      0.027414                0.00706   0.277313   0.551648     2.021855    45.491006      0.003003       0.017908     0.030186           0.00617    0.008266             0.002646     4.833242      6.146258       33.602542     569.356993         0.022832          0.157336        0.208624             0.065732       0.061867                0.018061    0.483918"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uni = Univariate.Univariate(df,quan)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "df_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d1d2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# RFE Feature Selection with Feature Support Print\n",
    "def rfeFeature(indep_X, dep_Y, n):\n",
    "    rfelist = []\n",
    "    selected_features = []\n",
    "\n",
    "    models = [\n",
    "        LogisticRegression(solver='lbfgs'),\n",
    "        SVC(kernel='linear', random_state=0),\n",
    "        RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0),\n",
    "        DecisionTreeClassifier(criterion='gini', max_features='sqrt', splitter='best', random_state=0)\n",
    "    ]\n",
    "    \n",
    "    for model in models:\n",
    "        print(\"\\nUsing estimator:\", model)\n",
    "        rfe = RFE(estimator=model, n_features_to_select=n)\n",
    "        rfe_fit = rfe.fit(indep_X, dep_Y)\n",
    "\n",
    "        selected = rfe_fit.support_\n",
    "        selected_indices = indep_X.columns[selected] if hasattr(indep_X, 'columns') else np.where(selected)[0]\n",
    "        print(\"Selected Features (indices or names):\", selected_indices)\n",
    "\n",
    "        transformed = rfe_fit.transform(indep_X)\n",
    "        rfelist.append(transformed)\n",
    "        selected_features.append(selected_indices)\n",
    "        \n",
    "    return rfelist, selected_features\n",
    "\n",
    "# Train/test split + scaling\n",
    "def split_scalar(indep_X, dep_Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.25, random_state=0)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Generic classification prediction\n",
    "def cm_prediction(classifier, X_test, y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    Accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm\n",
    "\n",
    "# Classifier wrappers\n",
    "def logistic(X_train, y_train, X_test, y_test):\n",
    "    classifier = LogisticRegression(random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def svm_linear(X_train, y_train, X_test, y_test):\n",
    "    classifier = SVC(kernel='linear', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def svm_NL(X_train, y_train, X_test, y_test):\n",
    "    classifier = SVC(kernel='rbf', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def Navie(X_train, y_train, X_test, y_test):\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def knn(X_train, y_train, X_test, y_test):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def Decision(X_train, y_train, X_test, y_test):\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def random(X_train, y_train, X_test, y_test):\n",
    "    classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "# Classification accuracy matrix\n",
    "def rfe_classification(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf): \n",
    "    index_names = ['Logistic', 'SVC', 'Random', 'DecisionTree']\n",
    "    columns = ['Logistic', 'SVMl', 'SVMnl', 'KNN', 'Navie', 'Decision', 'Random']\n",
    "    df = pd.DataFrame(index=index_names, columns=columns)\n",
    "\n",
    "    for i, idx in enumerate(index_names):\n",
    "        df.loc[idx] = [acclog[i], accsvml[i], accsvmnl[i], accknn[i], accnav[i], accdes[i], accrf[i]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d422261",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep = df[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
    "       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]\n",
    "# indep = df[['radius_mean', 'texture_se', 'radius_worst', 'concavity_worst', 'concave points_worst']]\n",
    "dep = df['diagnosis_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67ddd95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using estimator: LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (indices or names): Index(['radius_mean', 'texture_se', 'radius_worst', 'concavity_worst', 'concave points_worst'], dtype='object')\n",
      "\n",
      "Using estimator: SVC(kernel='linear', random_state=0)\n",
      "Selected Features (indices or names): Index(['smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst'], dtype='object')\n",
      "\n",
      "Using estimator: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Selected Features (indices or names): Index(['concave points_mean', 'radius_worst', 'perimeter_worst', 'area_worst', 'concave points_worst'], dtype='object')\n",
      "\n",
      "Using estimator: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Selected Features (indices or names): Index(['area_se', 'texture_worst', 'area_worst', 'concavity_worst', 'concave points_worst'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rfelist, selected_feats = rfeFeature(indep, dep, 5)\n",
    "\n",
    "acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf = [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff7b575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rfelist:   \n",
    "    X_train, X_test, y_train, y_test = split_scalar(i, dep)\n",
    "\n",
    "    _, acc, *_ = logistic(X_train, y_train, X_test, y_test)\n",
    "    acclog.append(acc)\n",
    "\n",
    "    _, acc, *_ = svm_linear(X_train, y_train, X_test, y_test)\n",
    "    accsvml.append(acc)\n",
    "\n",
    "    _, acc, *_ = svm_NL(X_train, y_train, X_test, y_test)\n",
    "    accsvmnl.append(acc)\n",
    "\n",
    "    _, acc, *_ = knn(X_train, y_train, X_test, y_test)\n",
    "    accknn.append(acc)\n",
    "\n",
    "    _, acc, *_ = Navie(X_train, y_train, X_test, y_test)\n",
    "    accnav.append(acc)\n",
    "\n",
    "    _, acc, *_ = Decision(X_train, y_train, X_test, y_test)\n",
    "    accdes.append(acc)\n",
    "\n",
    "    _, acc, *_ = random(X_train, y_train, X_test, y_test)\n",
    "    accrf.append(acc)\n",
    "\n",
    "result = rfe_classification(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea285a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.951049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.86014</td>\n",
       "      <td>0.86014</td>\n",
       "      <td>0.958042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.958042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.965035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Logistic      SVMl     SVMnl       KNN     Navie  Decision    Random\n",
       "Logistic      0.958042  0.951049  0.944056  0.937063   0.93007  0.944056  0.951049\n",
       "SVC           0.909091  0.916084  0.923077  0.902098   0.86014   0.86014  0.958042\n",
       "Random        0.951049  0.958042  0.965035  0.937063  0.951049  0.937063  0.958042\n",
       "DecisionTree  0.972028  0.972028  0.958042  0.979021  0.944056  0.923077  0.965035"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result for n=5\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31371445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1aeeac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indep = df[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
    "#        'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "#        'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "#        'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "#        'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "#        'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "#        'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "#        'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "#        'symmetry_worst', 'fractal_dimension_worst']]\n",
    "indep = df[['radius_mean', 'texture_se', 'radius_worst', 'concavity_worst', 'concave points_worst']]\n",
    "dep = df['diagnosis_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "873ec4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(indep,dep,test_size=1/3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ac1ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e59f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END ......penalty=l2, solver=newton-cg;, score=0.920 total time=   0.0s\n",
      "[CV 2/5] END ......penalty=l2, solver=newton-cg;, score=0.920 total time=   0.0s\n",
      "[CV 3/5] END ......penalty=l2, solver=newton-cg;, score=0.960 total time=   0.0s\n",
      "[CV 4/5] END ......penalty=l2, solver=newton-cg;, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END ......penalty=l2, solver=newton-cg;, score=0.974 total time=   0.0s\n",
      "[CV 1/5] END ..........penalty=l2, solver=lbfgs;, score=0.920 total time=   0.0s\n",
      "[CV 2/5] END ..........penalty=l2, solver=lbfgs;, score=0.920 total time=   0.0s\n",
      "[CV 3/5] END ..........penalty=l2, solver=lbfgs;, score=0.960 total time=   0.0s\n",
      "[CV 4/5] END ..........penalty=l2, solver=lbfgs;, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END ..........penalty=l2, solver=lbfgs;, score=0.974 total time=   0.0s\n",
      "[CV 1/5] END ......penalty=l2, solver=liblinear;, score=0.920 total time=   0.0s\n",
      "[CV 2/5] END ......penalty=l2, solver=liblinear;, score=0.933 total time=   0.0s\n",
      "[CV 3/5] END ......penalty=l2, solver=liblinear;, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END ......penalty=l2, solver=liblinear;, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END ......penalty=l2, solver=liblinear;, score=0.974 total time=   0.0s\n",
      "[CV 1/5] END ...........penalty=l2, solver=saga;, score=0.920 total time=   0.0s\n",
      "[CV 2/5] END ...........penalty=l2, solver=saga;, score=0.920 total time=   0.0s\n",
      "[CV 3/5] END ...........penalty=l2, solver=saga;, score=0.960 total time=   0.0s\n",
      "[CV 4/5] END ...........penalty=l2, solver=saga;, score=0.973 total time=   0.0s\n",
      "[CV 5/5] END ...........penalty=l2, solver=saga;, score=0.974 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(), n_jobs=1,\n",
       "             param_grid={&#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LogisticRegression(), n_jobs=1,\n",
       "             param_grid={&#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), n_jobs=1,\n",
       "             param_grid={'penalty': ['l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga']},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'solver':['newton-cg','lbfgs','liblinear','saga'],'penalty':['l2']}\n",
    "grid = GridSearchCV(LogisticRegression(),param_grid,refit=True,verbose=3,n_jobs=1,scoring='f1_weighted')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d20fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115   7]\n",
      " [  5  63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       122\n",
      "           1       0.90      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.94       190\n",
      "   macro avg       0.93      0.93      0.93       190\n",
      "weighted avg       0.94      0.94      0.94       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "re=grid.cv_results_\n",
    "grid_pred = grid.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,grid_pred)\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf_report = classification_report(y_test,grid_pred)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd182bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9370387881309454"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_macro=f1_score(y_test,grid_pred,average='weighted')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca55da36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903567984570877"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test,grid.predict_proba(x_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1655fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"finalized_model_LogisticRegression.sav\"\n",
    "pickle.dump(grid,open(filename,'wb'))\n",
    "\n",
    "\n",
    "scaler_filename = \"scaler.pkl\"\n",
    "pickle.dump(sc, open(scaler_filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec4885e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "loaded_model = pickle.load(open(\"finalized_model_LogisticRegression.sav\", 'rb'))\n",
    "scaler = pickle.load(open(\"scaler.pkl\", 'rb'))\n",
    "\n",
    "input_data = [[20.3, 1.2, 28.5, 0.45, 0.23]]\n",
    "\n",
    "scaled_input = scaler.transform(input_data)\n",
    "\n",
    "result = loaded_model.predict(scaled_input)\n",
    "print(result)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b47ed32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "loaded_model = pickle.load(open(\"finalized_model_LogisticRegression.sav\", 'rb'))\n",
    "scaler = pickle.load(open(\"scaler.pkl\", 'rb'))\n",
    "\n",
    "input_data = [[12.1, 0.4, 13.3, 0.02, 0.01]]\n",
    "\n",
    "scaled_input = scaler.transform(input_data)\n",
    "\n",
    "result1 = loaded_model.predict(scaled_input)\n",
    "print(result1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b49efc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
